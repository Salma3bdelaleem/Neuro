{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJtDPJMRvIcz",
        "outputId": "76405c93-c6ba-47e2-c3a7-18e43aa650be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 / Loss: [7.80761297]\n",
            "Epoch 10 / Loss: [2.34120161]\n",
            "Epoch 20 / Loss: [1.69906693]\n",
            "Epoch 30 / Loss: [1.34242418]\n",
            "Epoch 40 / Loss: [1.10238605]\n",
            "Epoch 50 / Loss: [0.92591578]\n",
            "Epoch 60 / Loss: [0.78937043]\n",
            "Epoch 70 / Loss: [0.68013418]\n",
            "Epoch 80 / Loss: [0.59067662]\n",
            "Epoch 90 / Loss: [0.51614184]\n",
            "Predicted 4th word: powerful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-cabb077b0a7c>:108: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  predicted_word = index_to_word[int(prediction)]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Prepare the dataset\n",
        "text = \"Machine learning is powerful\"\n",
        "words = text.split()\n",
        "\n",
        "# Create a dictionary to map words to indices\n",
        "word_to_index = {word: idx for idx, word in enumerate(set(words))}\n",
        "index_to_word = {idx: word for word, idx in word_to_index.items()}\n",
        "\n",
        "# Convert words to indices\n",
        "sequences = [[word_to_index[word] for word in words[i:i+3]] for i in range(len(words)-3)]\n",
        "targets = [word_to_index[words[i+3]] for i in range(len(words)-3)]\n",
        "\n",
        "# Convert sequences and targets to numpy arrays\n",
        "X = np.array(sequences)\n",
        "y = np.array(targets)\n",
        "\n",
        "# 2. Define the RNN class\n",
        "class SimpleRNN:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        # Initialize weights and biases\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Weights for input to hidden layer\n",
        "        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01\n",
        "        # Weights for hidden to hidden layer\n",
        "        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
        "        # Weights for hidden to output layer\n",
        "        self.Why = np.random.randn(output_size, hidden_size) * 0.01\n",
        "\n",
        "        # Biases\n",
        "        self.bh = np.zeros((hidden_size, 1))\n",
        "        self.by = np.zeros((output_size, 1))\n",
        "\n",
        "    def forward(self, X):\n",
        "        h = np.zeros((self.hidden_size, 1))\n",
        "        for t in range(X.shape[0]):\n",
        "            x_t = np.zeros((self.input_size, 1))\n",
        "            x_t[X[t]] = 1\n",
        "\n",
        "            h = np.tanh(np.dot(self.Wxh, x_t) + np.dot(self.Whh, h) + self.bh)\n",
        "\n",
        "        y = np.dot(self.Why, h) + self.by\n",
        "        return y, h\n",
        "\n",
        "    def predict(self, X):\n",
        "        output, _ = self.forward(X)\n",
        "        return np.argmax(output, axis=0)\n",
        "\n",
        "# 3. Train the RNN\n",
        "def train(model, X, y, epochs=100, learning_rate=0.01):\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for i in range(X.shape[0]):\n",
        "            x_seq = X[i]\n",
        "            target = y[i]\n",
        "\n",
        "            # Forward pass\n",
        "            y_pred, h = model.forward(x_seq)\n",
        "\n",
        "            # Compute the loss (cross-entropy loss)\n",
        "            loss = -np.log(y_pred[target])\n",
        "            total_loss += loss\n",
        "\n",
        "            # Backward pass (gradient descent)\n",
        "            dL_dy = y_pred\n",
        "            dL_dy[target] -= 1\n",
        "\n",
        "            # Gradients for output layer\n",
        "            dL_dWhy = np.dot(dL_dy, h.T)\n",
        "            dL_dby = dL_dy\n",
        "\n",
        "            # Gradients for hidden layer\n",
        "            dL_dh = np.dot(model.Why.T, dL_dy)\n",
        "            dL_dhraw = (1 - h ** 2) * dL_dh\n",
        "            dL_dWxh = np.dot(dL_dhraw, np.zeros((model.input_size, 1)).T)\n",
        "            dL_dWhh = np.dot(dL_dhraw, h.T)\n",
        "            dL_dbh = dL_dhraw\n",
        "\n",
        "            # Update weights using gradient descent\n",
        "            model.Wxh -= learning_rate * dL_dWxh\n",
        "            model.Whh -= learning_rate * dL_dWhh\n",
        "            model.Why -= learning_rate * dL_dWhy\n",
        "            model.bh -= learning_rate * dL_dbh\n",
        "            model.by -= learning_rate * dL_dby\n",
        "\n",
        "        # Print the loss every 10 epochs\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch} / Loss: {total_loss}\")\n",
        "\n",
        "# Initialize and train the model\n",
        "input_size = len(word_to_index)\n",
        "hidden_size = 10\n",
        "output_size = len(word_to_index)\n",
        "\n",
        "rnn = SimpleRNN(input_size, hidden_size, output_size)\n",
        "train(rnn, X, y)\n",
        "\n",
        "# 4. Test the model\n",
        "test_sequence = [word_to_index[word] for word in words[:3]]\n",
        "prediction = rnn.predict(np.array(test_sequence))\n",
        "predicted_word = index_to_word[int(prediction)]\n",
        "print(f\"Predicted 4th word: {predicted_word}\")\n"
      ]
    }
  ]
}